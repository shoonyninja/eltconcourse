<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html dir="ltr" xmlns="http://www.w3.org/1999/xhtml">

<!-- #BeginTemplate "../../../styles/dwt/training.dwt" -->

<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
<meta http-equiv="Content-Language" content="en-gb" />
<!-- #BeginEditable "doctitle" -->
<title>ELT Concourse: testing, assessment and evaluation</title>
<style type="text/css">
















































.auto-style4 {
	color: #000000;
}
.auto-style5 {
	font-size: small;
}
.auto-style6 {
	list-style-type: lower-alpha;
}
.auto-style10 {
	font-size: large;
}

.auto-style2 {
	padding-left: 5px;
}
.auto-style11 {
	font-size: medium;
	color: #000000;
	font-weight: bold;
}
.auto-style18 {
	padding-left: 2px;
}
.auto-style21 {
	border-left: medium none #666666;
	border-right: medium none #666666;
	border-top: medium none #666666;
	border-bottom: 1px solid #666666;
	padding-left: 2px;
}
.auto-style22 {
	border-left: 1px solid #666666;
	border-right: medium none #666666;
	border-top: 1px solid #666666;
	border-bottom: 1px none #666666;
	padding-left: 5px;
	padding-right: 2px;
}
.auto-style24 {
	border: 1px solid #666666;
}
.auto-style27 {
	border-left: medium none #666666;
	border-right: 1px solid #666666;
	border-top: 1px solid #666666;
	border-bottom: 1px solid #666666;
	color: #000000;
}
.auto-style29 {
	border-left: medium none #666666;
	border-right: 1px solid #666666;
	border-top: medium none #666666;
	border-bottom: 1px solid #666666;
}
.auto-style30 {
	border-left: 1px solid #666666;
	border-right: medium none #666666;
	border-top: 1px solid #666666;
	border-bottom: 1px solid #666666;
}
.auto-style31 {
	border-left: medium none #666666;
	border-right: 1px solid #666666;
	border-top: 1px solid #666666;
	border-bottom: medium none #666666;
	color: #000000;
}
.auto-style32 {
	border-left: 1px solid #666666;
	border-right: 1px solid #666666;
	border-top: 1px solid #666666;
	border-bottom: medium none #666666;
}
.auto-style33 {
	border-left: 1px solid #666666;
	border-right: medium none #666666;
	border-top: 1px solid #666666;
	border-bottom: medium none #666666;
}
.auto-style34 {
	border-left: 1px solid #666666;
	border-right: 1px solid #666666;
	border-top: medium none #666666;
	border-bottom: 1px solid #666666;
}
.auto-style35 {
	border-left: 1px solid #666666;
	border-right: medium none #666666;
	border-top: medium none #666666;
	border-bottom: 1px solid #666666;
}
.auto-style36 {
	border-left: 1px solid #666666;
	border-right: 1px solid #666666;
	border-top: 1px solid #666666;
	border-bottom: medium none #666666;
	text-align: left;
}
.auto-style37 {
	border: 1px solid #666666;
	text-align: left;
}
.auto-style38 {
	border-left: 1px solid #666666;
	border-right: 1px solid #666666;
	border-top: medium none #666666;
	border-bottom: 1px solid #666666;
	text-align: left;
}
.auto-style39 {
	border-left: 1px solid #666666;
	border-right: medium none #666666;
	border-top: 1px solid #666666;
	border-bottom: medium none #666666;
	text-align: left;
}
.auto-style40 {
	border-left: 1px solid #666666;
	border-right: medium none #666666;
	border-top: 1px solid #666666;
	border-bottom: 1px solid #666666;
	text-align: left;
}
.auto-style41 {
	border-left: 1px solid #666666;
	border-right: medium none #666666;
	border-top: medium none #666666;
	border-bottom: 1px solid #666666;
	text-align: left;
}
.smallbluefont {
	color: #000080;
	font-size: small;
	font-style: normal;
}
.auto-style42 {
	padding-left: 4px;
}
.auto-style44 {
	border-left: medium none #666666;
	border-right: medium none #666666;
	border-top: 1px solid #666666;
	border-bottom: 1px none #666666;
}
.auto-style49 {
	border-left: medium none #666666;
	border-right: 1px solid #666666;
	border-top: 1px solid #666666;
	border-bottom: 1px solid #666666;
}
.auto-style50 {
	border-left: medium none #666666;
	border-right: 1px solid #666666;
	border-top: 1px solid #666666;
	border-bottom: 1px none #666666;
}
.auto-style51 {
	border-left: medium none #666666;
	border-right: medium none #666666;
	border-top: 1px solid #666666;
	border-bottom: 1px solid #666666;
}
.auto-style52 {
	border-left: medium none #666666;
	border-right: 1px solid #666666;
	border-top: 1px solid #666666;
	border-bottom: medium none #666666;
}
.auto-style53 {
	border-left: 1px solid #666666;
	border-right: medium none #666666;
	border-top: 1px solid #666666;
	border-bottom: medium none #666666;
	padding-left: 5px;
	padding-right: 2px;
}
.auto-style54 {
	color: #0099CC;
}
</style>
<meta content="ELT Concourse English language analysis and teaching guides. Testing, assessment and evaluation" name="description" />
<script type="text/javascript">
<!--
function FP_swapImg() {//v1.0
 var doc=document,args=arguments,elm,n; doc.$imgSwaps=new Array(); for(n=2; n<args.length;
 n+=2) { elm=FP_getObjectByID(args[n]); if(elm) { doc.$imgSwaps[doc.$imgSwaps.length]=elm;
 elm.$src=elm.src; elm.src=args[n+1]; } }
}

function FP_preloadImgs() {//v1.0
 var d=document,a=arguments; if(!d.FP_imgs) d.FP_imgs=new Array();
 for(var i=0; i<a.length; i++) { d.FP_imgs[i]=new Image; d.FP_imgs[i].src=a[i]; }
}

function FP_getObjectByID(id,o) {//v1.0
 var c,el,els,f,m,n; if(!o)o=document; if(o.getElementById) el=o.getElementById(id);
 else if(o.layers) c=o.layers; else if(o.all) el=o.all[id]; if(el) return el;
 if(o.id==id || o.name==id) return o; if(o.childNodes) c=o.childNodes; if(c)
 for(n=0; n<c.length; n++) { el=FP_getObjectByID(id,c[n]); if(el) return el; }
 f=o.forms; if(f) for(n=0; n<f.length; n++) { els=f[n].elements;
 for(m=0; m<els.length; m++){ el=FP_getObjectByID(id,els[n]); if(el) return el; } }
 return null;
}

function FP_changeProp() {//v1.0
 var args=arguments,d=document,i,j,id=args[0],o=FP_getObjectByID(id),s,ao,v,x;
 d.$cpe=new Array(); if(o) for(i=2; i<args.length; i+=2) { v=args[i+1]; s="o"; 
 ao=args[i].split("."); for(j=0; j<ao.length; j++) { s+="."+ao[j]; if(null==eval(s)) { 
  s=null; break; } } x=new Object; x.o=o; x.n=new Array(); x.v=new Array();
 x.n[x.n.length]=s; eval("x.v[x.v.length]="+s); d.$cpe[d.$cpe.length]=x;
 if(s) eval(s+"=v"); }
}
// -->
</script>
<!-- #EndEditable -->
<meta content="language analysis,eltconcourse,English grammar,free English language teaching materials,CELTA,Delta,language guides,free Delta training,free CELTA training,free ELT Training materials,teacher training,ELT,learning English,teaching English,English Language Teaching,ESOL,EFL,English as a Foreign Language" name="keywords" />
<link href="../../../styles/mainstyle.css" rel="stylesheet" type="text/css" />
<link href="../../../styles/training.css" rel="stylesheet" type="text/css" />
<style type="text/css">
</style>
</head>

<body>
	<!-- Begin Masthead -->
	<div id="masthead" >
		<table style="width: 100%; border-bottom: #000080 solid">
			<tr>
				<td style="width: 135px">
				<img alt="logo" height="49" src="../../../gfx/logo.png" width="78" /></td>
				<td valign="bottom">
				<span class="orangexxlargebold">ELT </span>
				<span class="bluexxlargebold">Concourse teacher training</span></td>
			</tr>
		</table>
	</div>
	<!-- End Masthead -->
	<!-- Begin Content -->
			<!-- Begin Sidebar -->
		<div id="sidebartt">
			<ul>
				<li><a href="../../../index.html">ELT Concourse home</a></li>
				<li><a href="../../../a-z_index.html">A-Z site index</a></li>
				<li><a href="../../training_index.html">Teacher training index</a></li>
				<li><a href="../../../development/development_index.html">Teacher development</a></li>
				<li><a href="../../../teachers/teachers.html">For teachers</a></li>
				<li><a href="../../trainers/trainers_index.html">For trainers</a></li>
				<li>
				<a href="../../../academic_management/academic_management_index.html">For managers</a></li>
				<li><a href="../../../learners/learners.html">For learners</a></li>
				<li><a href="../../common/about_language.html">About language</a></li>
				<li><a href="../../../questions/questions.html">Language questions</a></li>
				<li class="whiteback">Other areas</li>
				<li><a href="../indexes_is/eap_index_is.html">Academic English</a></li>
				<li><a href="../indexes_is/be_index_is.html">Business English</a></li>
				<li><a href="../../entering/introduction_to_elt.html">Entering ELT</a></li>
				<li><a href="../../courses/courses_index.html">Courses index</a></li>
				<li><a href="../../courses/basic/introduction_basic.html">Basic ELT course</a></li>
				<li><a href="../../tkt/tkt_index.html">TKT</a></li>
				<li><a href="../../bridge/bridge_index.html">The Bridge</a></li>
				<li><a href="../../courses/lacourse/index_la_course.html">Language analysis</a></li>
				<li>
				<a href="../../courses/training_to_train/training_to_train_index.html">Training to train</a></li>
				<li><a href="../../courses/transcription1/transcription.html">Transcription</a></li>
				<li><a href="../../glossaries/glossary_index.html">Glossaries</a></li>
				<li><a href="../../../articles/articles.html">Articles</a></li>
			</ul>
		</div>
		<!-- End Sidebar -->
		<!-- Begin Content -->
		
		<div id="toppicture" style="text-align: left; background-color: white; padding: 0px; margin-left: 140px;">
				<img alt="Concourse 2" height="207" src="../../../images/concourse2blue.jpg" width="310" /></div>
		
			<!-- #BeginEditable "content" -->
		
			<!-- #BeginEditable "content" -->
		
		<div id="content">
	
	
	<h1>Testing, assessment and evaluation</h1>
		<p>
		<img alt="test" height="207" src="../../images/write_test310.jpg" width="310" /></p>
		<p>Gentle warning: this is a complex area which is littered (some might 
		say infested) with 
		terminology.&nbsp; You may like to take it a bit at a time.</p>
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="changing face" height="166" src="../../images/face_change250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>The changing face of testing: a little history</h2>
					</td>
				</tr>
				</table>
		<p>Over the years, what we test and how we test it in our profession 
		have seen great changes.&nbsp; Here are three citations that show how.</p>
		<ul class="greybullet">
			<li><span class="auto-style4"><em>The more ambitious we are in 
		testing the communicative competence of a learner, the more 
		administratively costly, subjective and unreliable the results are.</em><br />
			<span class="auto-style5">(Corder, 1973: 364)</span></span></li>
			<li><span class="auto-style4"><em>The measurement of communicative proficiency is a job worth doing, 
		and the task is ultimately as feasible one.</em><br />
			<span class="auto-style5">(Morrow, in Alderson JC, Hughes, A (Eds.), 1979: 14)</span></span></li>
			<li><span class="auto-style4"><em>It is assumed in this book that it is usually communicative ability 
		which we want to test.</em><br /><span class="auto-style5">(Hughes, 1989: 19)</span></span></li>
		</ul>
		<p>In what follows, it is not assumed that it is always communicative 
		ability which we want to test but that's usually the case and definitely the way to bet.</p>
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="define" height="166" src="../../images/dictionary_idea250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Defining terms</h2>
					</td>
				</tr>
				</table>
		<p>Why the triple title?&nbsp; Why testing <span class="style_underline">
		and</span> assessment <span class="style_underline">and</span> 
		evaluation?&nbsp; Well, the terms are different and they mean different 
		things to different people.</p>
		<p>If you ask Google to define 'assess', it returns "<span class="auto-style4"><em>evaluate 
		or estimate the nature, ability, or quality of</em></span>".<br />
		If you then ask it to define 'evaluate', it returns "<span class="auto-style4"><em>form 
		an idea of the amount, number, or value of; assess</em></span>".<br />
		The meaning of the verbs is, therefore, pretty much the same but they 
		are used in English Language Teaching in subtly different ways.</p>
		<p>When we are talking about giving people a test and recording scores etc., 
		we would normally refer to this as an assessment procedure.<br />
		If, on 
		the other hand, we are talking about looking back over a course or a 
		lesson and deciding what went well, what was learnt and how people 
		responded, we would prefer the term 'evaluate' as it seems to describe a 
		wider variety of data input (testing, but also talking to people and 
		recording impressions and so on).&nbsp; Evaluation doesn't have to be very elaborate.&nbsp; 
		The term could be used to describe nodding to accept an answer in class up to formal examinations 
		set by international testing bodies but at that end of the cline, we are 
		more likely to talk about assessment and examining.</p>
		<p>Another difference in use is that when we measure success for ourselves 
		(as in teaching a lesson) we are conducting evaluation; when someone 
		else does it, it's called assessment.</p>
		<p>In what follows, therefore, the terms are used to mean the same thing 
		but the choice of which term to use will be made to be appropriate to what we are 
		discussing.</p>
		<p>How about 'testing'?&nbsp; In this guide 'testing' is seen as a form of 
		assessment but, as we shall see, testing comes in all shapes and sizes.&nbsp; 
		Look at it this way:</p>
		<table cellpadding="0" cellspacing="3" style="width: 100%">
			<tr>
				<td>
				<img alt="eta" height="209" src="../../imagesgraphics/eta.png" width="310" /></td>
				<td valign="middle" class="auto-style42">As you see, testing sits uncomfortably between 
				evaluation and assessment.&nbsp; If testing is informal and 
				classroom based, it forms part of evaluation.&nbsp; A bi-weekly 
				progress test is part of evaluation although learners may see it 
				as assessment.&nbsp; When testing is formal and externally 
				administered, it's usually called examining.<br />
				Testing can be anything in between.&nbsp; For example, an 
				institution's end-of-course test is formal testing (not 
				examining) and a concept-check question to see if a learner has 
				grasped a point is informal testing and part of evaluating the 
				learning process in a lesson.<br />
				<a href="testinghp2.htm">Try a short matching test on this area</a>.&nbsp; 
				It doesn't matter too much if you have all the answers right.</td>
			</tr>
		</table>
		<br />
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="why" height="166" src="../../images/question_why_boy250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Why evaluate, assess or test?</h2>
					</td>
				</tr>
				</table>
		<p>It's not enough to be clear about what you want people to learn and 
		to design a teaching programme to achieve the objectives.&nbsp; We must 
		also have some way of knowing whether the objectives have been achieved.<br />
		That's called testing.</p>
			<p class="indentpara"><em>If you can't measure it, you can't improve 
			it</em><br /><span class="smallbluefont">Peter Drucker</span></p>
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="types" height="166" src="../../images/variety_hats250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Types of evaluation, assessment and testing</h2>
					</td>
				</tr>
				</table>
		<p>We need to get this clear before we can 
		look at the area in any detail.</p>
		<dl>
	<dt class="auto-style10"><strong>Initial vs. Formative vs. Summative evaluation</strong></dt>
	<dd><span class="auto-style4">Initial testing</span> is often one of two things in ELT: a diagnostic test to 
	help formulate a syllabus and course plan or a placement test to put 
	learners into the right class for their level.<br />
	<span class="auto-style4">Formative testing</span> is used to enhance and adapt the learning programme.&nbsp; 
	Such tests help both teachers and learners to see what has been learned and 
	how well and to help set targets.&nbsp; It has been called educational 
	testing.&nbsp; Formative evaluation may refer to adjusting the programme or 
	helping people see where they are.&nbsp; In other words, it may targeted at 
	teaching or learning (or both).<br />
	<span class="auto-style4">Summative tests</span>, on the other hand, seek to measure how well a set of 
	learning objectives has been achieved at the end of a period of instruction.<br />
		Robert Stake describes the difference this way:
	<span class="auto-style4"><em>When the cook 
		tastes the soup, that's formative.&nbsp; When the guests taste the soup, 
		that's summative.</em></span> <span class="auto-style5">(cited in 
	Scrivener, 1991:169)</span>.<br />
	There is more on the distinctions and arguments surrounding formative and 
	summative testing below.</dd>
			<dt class="auto-style10"><strong>Informal vs. Formal evaluation</strong></dt>
			<dd><span class="auto-style4">Formal evaluation</span> usually implies some kind of written document 
			(although it may be an oral test) and some kind of scoring system.&nbsp; 
			It could be a written test, an interview, an on-line test, a piece of 
			homework or a number of other things.<br />
			<span class="auto-style4">Informal evaluation</span> may include some kind of document but there's 
			unlikely to be a scoring system as such and evaluation might 
			include, for example, simply observing the learner(s), listening to 
			them and responding, giving them checklists, peer- and 
			self-evaluation and a number of other procedures.</dd>
			<dt class="auto-style10"><strong>Objective vs. Subjective assessment</strong></dt>
			<dd><span class="auto-style4">Objective assessment</span> (or, more usually, testing) is 
			characterised by tasks in which there is only one right answer.&nbsp; 
			It may be a multiple-choice test, a True/False test or any other 
			kind of test where the result can readily be seen and is not subject 
			to the marker's judgement.<br />
			<span class="auto-style4">Subjective tests</span> are those in which questions are open ended and the 
			marker's judgement is important.<br />
			Of course, there are various levels of test on the 
			subjective-objective scale.</dd>
			<dt class="auto-style10"><strong>Criterion-referencing vs. Norm-referencing in tests</strong></dt>
			<dd><span class="auto-style4">Criterion-referenced tests</span> are those in which the result is 
			measured against a scale (e.g., by grades from A to E or by a score 
			out of 100).&nbsp; The object is to judge how well someone did 
			against a set of objective criteria independently of any other 
			factors.&nbsp; A good example is a driving test.<br />
			<span class="auto-style4">Norm-referencing</span> is a way of measuring students against each other.&nbsp; 
			For example, if 10% of a class are going to enter the next class up, 
			a norm-referenced test will not judge how well they achieved a task 
			in a test but how well they did against the other students in the 
			group.&nbsp; Some universities apply norm-referencing tests to 
			select undergraduates.</dd>
</dl>
		<p>There's a matching exercise to help you see if you have 
		understood this section.&nbsp; <a href="testinghp1.htm">Click here to do 
		it</a>.</p>
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="good or bad" height="166" src="../../images/goodbad250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Testing &ndash; what makes a good test?</h2>
					</td>
				</tr>
				</table>
		<p><span class="auto-style4"><em>You teach a child to read, and he or 
		her will be able to pass a literacy test</em></span>.<br />
		<span class="auto-style5">George W. Bush</span></p>
		<p>The first thing to get clear is the distinction between testing and 
		examining.<br />
		Complete the gaps in following in your head and then click on the table 
		to see what answers you get.<br />
		<img id="img1" alt="test vs exam task" height="225" onclick="FP_swapImg(0,0,/*id*/'img1',/*url*/'../../imagesgraphics/testvsexamans.png')" src="../../imagesgraphics/testvsexamtask.png" width="400" /></p>
		<p>One more term (sorry):<br />
		The term 'backwash' or, sometimes, 'washback', is used to describe the 
		effect on teaching that knowledge of the format of a test or examination 
		has.&nbsp; For example, if we are preparing people for a particular style of 
		examination, some (perhaps nearly all) of the teaching will be focused 
		on training learners to perform well in that test format.</p>
			<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="form" height="166" src="../../images/form_pottery250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Formative <em>vs.</em> summative testing</h2>
					</td>
				</tr>
				</table>
			<p>In recent years in mainstream education in the UK especially but 
			also elsewhere, the role of formative assessment has been 
			investigated at some length and the findings appear to show that 
			formative assessment wins hands down.<br />
			The arguments rests on two connected contrasts between summative and 
			formative assessment:</p>
			<ol>
				<li>Traditional school-based assessment programmes are generally 
				summative insofar as they attempt to ascertain accurate 
				information about the attainment (or not) of educational goals.&nbsp; 
				Normally, such assessment occurs after a period of teaching 
				(which may be as much as a school year or even longer) and 
				involves assigning grades to the individuals' performance.<br />
				Almost all mainstream educational institutions carry out formal, 
				summative assessment on a regular basis.<br />
				Formative assessment, on the other hand, occurs throughout the 
				teaching programme at any time when information needs to be 
				gathered and that information is not used to assign grades but 
				to supply <strong>both</strong> the learners and the teachers 
				(and the institution) with evidence about how learning is 
				developing (not where it has got to).<br />
				The evidence is then used by all parties to see how the teaching 
				and learning activities and content need to be adjusted to reach 
				the goals of the curriculum.<br />
				The outcome of this form of assessment should be to allow 
				teachers and institutions to adjust their programmes and 
				behaviours but also, crucially, to allow the learners to adjust 
				their behaviour and working practices, too.</li>
				<li>Summative assessment emphasises grades and reports on 
				success or failure.&nbsp; It is, frequently, a demotivating and 
				unhappy experience for many.<br />
				Formative assessment focuses on learning and promoting 
				motivation to learn because it emphasises achievement rather 
				than failure.&nbsp; For this reasons, it is sometimes dubbed AfL 
				(Assessment for Learning).</li>
			</ol>
			<p>There are important implications for all teaching and learning 
			settings in this because the claims made for the advantages of 
			formative over summative assessment are quite grand.&nbsp; It is 
			averred that formative assessment:</p>
			<ol>
				<li>makes teaching more effective because it provides data in an 
				ongoing way on which the teacher can act and to which the 
				learners can react</li>
				<li>has a positive effect on achievement because goals are set 
				rationally and realistically and are achievable in small steps</li>
				<li>empowers learners and encourages them to take more 
				responsibility for their own learning and progress</li>
				<li>acts as a corrective to prevent misunderstandings of what is 
				required because feedback on learning success is specific and 
				targeted (unlike a grade on an examination certificate)</li>
				<li>is cooperative because learners can involve each other in 
				assessing their own progress</li>
				<li>encourages autonomy because learners can acquire the skills 
				of self-assessment which can be transferred to other settings</li>
			</ol>
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="types" height="166" src="../../images/variety_flowers250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Types of tests</h2>
					</td>
				</tr>
				</table>
		<p>There are lots of these but the major categories are</p>
		<table class="tableblueborder" style="width: 75%" cellpadding="3" cellspacing="0">
			<tr>
				<td class="auto-style29"><strong>Test types</strong></td>
				<td class="auto-style34"><strong>What the tests are intended to do</strong></td>
				<td class="auto-style35"><strong><em>Example</em></strong></td>
			</tr>
			<tr>
				<td class="auto-style27">aptitude tests</td>
				<td class="auto-style24">test a learner’s general ability to 
				learn a language rather than the ability to use a particular 
				language</td>
				<td class="auto-style30"><em>The Modern Language Aptitude Test (US 
				Army) and its successors</em></td>
			</tr>
			<tr>
				<td class="auto-style27">achievement tests</td>
				<td class="auto-style24">measure students' performance at the end 
				of a period of study to evaluate the effectiveness of the 
				programme</td>
				<td class="auto-style30"><em>an end-of-course or end-of-week etc. 
				test (even a mid-lesson test)</em></td>
			</tr>
			<tr>
				<td class="auto-style27">diagnostic tests</td>
				<td class="auto-style24">discover learners' strengths and 
				weaknesses for planning purposes</td>
				<td class="auto-style30"><em>a test set early in a programme to plan 
				the syllabus</em></td>
			</tr>
			<tr>
				<td class="auto-style31">proficiency tests</td>
				<td class="auto-style32">test a learner’s ability in the language 
				regardless of any course they may have taken</td>
				<td class="auto-style33"><em>public examinations such as FCE etc. but 
				also placement tests</em></td>
			</tr>
			<tr>
				<td class="auto-style31">barrier tests</td>
				<td class="auto-style32">a special type of test designed to 
				discover if someone is ready to take a course</td>
				<td class="auto-style33"><em>a pre-course test which assesses 
				the learner's current level with respect to the intended course 
				content</em></td>
			</tr>
		</table>
		<p>As far as day-to-day classroom use is concerned, teachers are mostly 
		involved in writing and administering achievement tests as a way of 
		telling them and the learners how successfully what has been taught has 
		been learned.</p>
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="items" height="166" src="../../images/bricabrac_b250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Types of test items</h2>
					</td>
				</tr>
				</table>
		<p>Here, again, are some definitions of the terminology you need to 
		think or write about testing.</p>
		<dl>
	<dt class="auto-style10"><strong>alternate response</strong></dt>
	<dd>This sort of item is probably most familiar to language teachers as a 
	<span class="style_black">True / False</span> test.&nbsp; (Technically, only two possibilities are 
	allowed.&nbsp; If you have a <span class="style_black">True / False / Don't know</span> test, then it's 
	really a multiple-choice test.)</dd>
			<dt class="auto-style10"><strong>multiple-choice</strong></dt>
			<dd>This is sometimes called a fixed-response test.&nbsp; Typically, 
			the correct answer must be chosen from three or four alternatives.&nbsp; 
			The 'wrong' items are called the distractors.</dd>
			<dt class="auto-style10"><strong>structured response</strong></dt>
			<dd>In tests of this sort, the subject is given a structure in which 
			to form the answer.&nbsp; Sentence completion items of the sort 
			which require the subject to expand a sentence such as 
			<span class="style_black">He / come/ my 
			house / yesterday / 9 o'clock</span> into <em>He came to my house at 9 
			o'clock yesterday </em>are tests of this sort as are writing tests 
			in which the test-taker is constrained to include a list of items in 
			the response.</dd>
			<dt class="auto-style10"><strong>free response</strong></dt>
			<dd>In these tests, no guidance is given other than the rubric and 
			the subjects are free to write or say what they like.&nbsp; A hybrid 
			form of this and a structured response item is one where the subject 
			is given a list of things to include in the response but that is 
			usually called a structured response test, especially when the list 
			of things to include covers most of the writing and little is left 
			to the test-taker's imagination.</dd>
</dl>
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="ways" height="166" src="../../images/ways250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Ways of testing and marking</h2>
					</td>
				</tr>
				</table>
		<p>Just as there are ways to design test items and purposes for testing 
		(see above), there are ways to test in general.&nbsp; Here are 
		the most important ones.</p>
		<table class="tableblueborder" style="width: 90%" cellpadding="3" cellspacing="0">
			<tr>
				<td class="auto-style29"><strong>Methodology</strong></td>
				<td class="auto-style38"><strong>Description</strong></td>
				<td class="auto-style41"><strong><em>Example</em></strong></td>
				<td class="auto-style41"><strong><em>Comments</em></strong></td>
			</tr>
			<tr>
				<td class="auto-style27">direct testing</td>
				<td class="auto-style37">testing a particular skill by getting 
				the student to perform that skill</td>
				<td class="auto-style40"><em>testing whether someone can write a 
				discursive essay by asking them to write one</em></td>
				<td class="auto-style40">The argument is that this kind of test 
				is more reliable because it tests the outcomes, not just the 
				individual skills and knowledge that the test-taker needs to 
				deploy</td>
			</tr>
			<tr>
				<td class="auto-style27">indirect testing</td>
				<td class="auto-style37">trying to test the abilities which 
				underlie the skills we are interested in</td>
				<td class="auto-style40"><em>testing whether someone can write a 
				discursive essay by testing their ability to use contrastive 
				markers, modality, hedging etc.</em></td>
				<td class="auto-style40">Although this kind of test is less 
				reliable in testing whether the individual skills can be 
				combined, it is easier to mark objectively</td>
			</tr>
			<tr>
				<td class="auto-style27">discrete-point testing</td>
				<td class="auto-style37">a test format with many items requiring 
				short answers which each target a defined area</td>
				<td class="auto-style40"><em>placement tests are usually of this sort 
				with multiple-choice items focused on vocabulary, grammar, 
				functional language etc.</em></td>
				<td class="auto-style40">These sorts of tests can be very 
				objectively marked and need no judgement on the part of the 
				markers</td>
			</tr>
			<tr>
				<td class="auto-style27">integrative testing</td>
				<td class="auto-style37">combining many language elements to do 
				the task</td>
				<td class="auto-style40"><em>public examinations contain a good deal 
				of this sort of testing with marks awarded for various elements: 
				accuracy, range, communicative success etc.</em></td>
				<td class="auto-style40">Although the task is integrative, the 
				marking scheme is designed to make the marking non-judgemental 
				by breaking down the assessment into discrete parts</td>
			</tr>
			<tr>
				<td class="auto-style27">subjective marking</td>
				<td class="auto-style37">the marks awarded depend on someone’s 
				opinion or judgement</td>
				<td class="auto-style40"><em>marking an essay on the basis of how 
				well you think it achieved the task</em></td>
				<td class="auto-style40">Subjective marking has the great 
				disadvantage of requiring markers to be very carefully monitored 
				and standardised to ensure that they all apply the same 
				strictness of judgement consistently</td>
			</tr>
			<tr>
				<td class="auto-style27">objective marking</td>
				<td class="auto-style37">marking where only one answer is 
				possible – right or wrong</td>
				<td class="auto-style40"><em>machine marking a multiple-choice test 
				completed by filling in a machine-readable mark sheet</em></td>
				<td class="auto-style40">This obviously makes the marking very 
				reliable but it is not always easy to break language knowledge 
				and skills down into digital, right-wrong elements.</td>
			</tr>
			<tr>
				<td class="auto-style27">analytic marking</td>
				<td class="auto-style37">the separate marking of the constituent 
				parts that make up the overall performance</td>
				<td class="auto-style40"><em>breaking down a task into parts and 
				marking each bit separately (see integrative testing, above)</em></td>
				<td class="auto-style40">This is very similar to integrative 
				testing but care has to be taken to ensure that the breakdown is 
				really into equivalent and usefully targeted areas</td>
			</tr>
			<tr>
				<td class="auto-style31">holistic marking</td>
				<td class="auto-style36">different activities are included in the 
				overall description to produce a multi-activity scale</td>
				<td class="auto-style39"><em>marking an essay on the basis of how 
				well it achieves its aims (see subjective marking, above)</em></td>
				<td class="auto-style39">The term holistic refers to seeing the 
				whole picture and such test marking means that it has the same 
				drawbacks as subjective marking, requiring monitoring and 
				standardisation of markers.</td>
			</tr>
		</table>
			<br />
		Naturally, these types of testing and marking can be combined in any 
		assessment procedure and often are.<br />
		For example, a piece of writing in answer to a structured response test 
		item can be marked by awarding points for mentioning each required 
		element (objective) and then given more points for overall effect on the 
		reader (subjective).<br />
		<br />
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="three concepts" height="166" src="../../images/three_candles250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Three fundamental concepts:<br />
					reliability, validity and practicality</h2>
					</td>
				</tr>
				</table>
		<ol>
			<li><strong>Reliability</strong><br />
			This refers, oddly, to how reliable the test is.&nbsp; It 
			answers this question:<br />
			<span class="style_black"><em>Would a 
				candidate get the same result whether they took the test in 
				London or Kuala Lumpur or if they took it on Monday or Tuesday?</em></span><br />
			This is sometimes referred to as the test-retest test.&nbsp; A 
			reliable test is one which will produce the same result if it is 
			administered again.&nbsp; Statisticians reading this will 
			immediately understand that it is the correlation between 
			the two test results that measures reliability.</li>
			<li><strong>Validity</strong><br />
			Two questions here:<ol class="auto-style6">
				<li><span class="style_black"><em>Does the test measure what we say it measures?</em></span><br />
				For example, if we set out to test someone's ability to 
				participate in informal spoken transactions, do the test items 
				we use actually test that ability or something else?</li>
				<li><span class="style_black"><em>Does the test contain a relevant and representative sample 
				of what it is testing?</em></span><br />
				For example, if we are testing someone's ability to write a 
				formal email, are we getting them to deploy the sorts 
				of language they actually need to do that?</li>
			</ol>
			</li>
			<li><strong>Practicality</strong><br />
			Is the test deliverable in practice?&nbsp; Does it take hours to do and 
			hours to mark or is it quite reasonable in this regard?</li>
		</ol>
		<p><span class="auto-style4">For examining bodies</span>, the most important criteria are practicality 
		and reliability.&nbsp; They want their examinations to be trustworthy and easy 
		(and cheap) 
		to administer and mark.<br />
		<span class="auto-style4">For classroom test makers</span>, the overriding criterion is validity.&nbsp; 
		We want a test to test what we think it tests and we aren't interested 
		in getting people to do it twice or making it (very) easy to mark.</p>
		<p>There's a matching test to help you see if you have 
		understood this section.&nbsp; <a href="testinghp3.htm">Click here to do 
		it</a>.</p>
		<p>So:</p>
		<ol>
			<li>How can we make a test reliable?</li>
			<li>How can we make a test valid?</li>
		</ol>
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="reliability" height="166" src="../../images/link_rope_mooring250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2><a name="rely"></a>Reliability</h2>
					</td>
				</tr>
				</table>
		<p>If you have been asked to write a placement test or an end-of-course 
		test that will be used again and again, you need to consider reliability 
		very carefully.&nbsp; There's no use having, e.g., an end-of-course test which 
		produces wildly different results every time you administer it and if a 
		placement test did that, most of your learners would end up in the wrong 
		class.<br />
		To make a test more reliable, we need to consider two things:</p>
		<ol class="auto-style6">
			<li>Make the candidates’ performance as consistent as possible.</li>
			<li>Make the scoring as consistent as possible.</li>
		</ol>
		<p>How would you do this?&nbsp; 
		<a href="#rely" onclick="FP_changeProp(/*id*/'reliability',0,'style.visibility','visible'); FP_changeProp(/*id*/'reliabilitylist',0,'style.visibility','visible')">Think for a minute and then click here</a>.</p>
		<p>
		<img alt="reliability" height="283" src="../../imagesgraphics/reliability.png" width="465" /></p>
		<dl id="reliabilitylist" style="visibility: hidden">
			<dt class="auto-style11"><strong>Circumstances</strong></dt>
			<dd>you can't always control this but we need to make an effort to 
			see that things like noise levels, room temperature, level of 
			distraction etc. are kept stable.</dd>
			<dt class="auto-style11"><strong>Marking</strong></dt>
			<dd>the more subjectively marked a test is (e.g., an interview to 
			assess oral, communicative competence), the more carefully we have 
			to standardise markers.&nbsp; The fewer markers you have, the easier 
			it is to do this.&nbsp; If you mark subjectively, try to ensure at 
			least double marking of most work.</dd>
			<dt class="auto-style11"><strong>Uniformity</strong></dt>
			<dd>if you have parallel versions of the same test, are they really 
			parallel?</dd>
			<dt class="auto-style11"><strong>Quantity</strong></dt>
			<dd>the more evidence you have, the more reliable will be the 
			judgement.&nbsp; That's why chess matches, football competitions, 
			shooting events and so on do not rely on a single game or attempt.&nbsp; 
			The aim is to gather more than a one-off piece of data.&nbsp; The 
			key here is ensuring coverage.&nbsp; The longer a test is, the more 
			areas you can cover.<br />
			The down side, of course, is that the longer a test is, the longer 
			it takes to mark and the more tired and dispirited the test-takers 
			may become.</dd>
			<dt class="auto-style11"><strong>Constraints</strong></dt>
			<dd>the more freedom you give test subjects to produce language, the 
			more able they are to avoid using structures and language they are 
			unsure of.&nbsp; In other words, free tasks are error avoiding but 
			controlled tasks allow you more reliably to gauge whether the targets 
			can be successfully achieved.<br />
			Compare, for example:<br />
			<span class="style_black"><em>Write 500 words about how to improve 
			your school.</em></span><br />
			with<br />
			<span class="style_black"><em>Write 500 words about how to improve 
			your school focusing on facilities, teaching, sports equipment and 
			technology.&nbsp; Suggest at least one improvement in each area.</em></span><br />
			The second is a structured response test and the rubric forces the test subjects to produce language in 
			specific areas but the first is a free response test and allows them to avoid anything they are 
			not sure about.</dd>
			<dt class="auto-style11"><strong>Make rubrics clear</strong></dt>
			<dd>Any misunderstanding of what's required undermines reliability.<br />
			Learners vary in their familiarity with certain types of task and 
			some may, for example, instantly recognise what they need to do from 
			a glance at the task.&nbsp; Others may need more explicit direction 
			and even teaching.&nbsp; Making the rubric clear contributes to 
			levelling the playing field.</dd>
		</dl>
		<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="validity" height="166" src="../../images/stamp_valid250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Validity</h2>
					</td>
				</tr>
				</table>
		<p>
		If you are writing a test for your own class or an individual learner 
		or group of students for whom you want to plan a course, or see how a 
		course is going, then validity 
		is most important for you.&nbsp; You will only be running the test once 
		and it isn't important that the results are correlated to other tests.&nbsp; 
		All you want to ensure is that the test is testing what you think it's 
		testing so the results will be meaningful.<br />
		There are five different sorts of validity to consider.&nbsp; Here they 
		are:</p>
		<p>
		<img alt="validity" height="174" src="../../imagesgraphics/validity.png" width="600" /></p>
		<p>
		To explain:</p>
		<dl>
	<dt class="auto-style11"><strong>Face validity</strong></dt>
	<dd>Students won't perform at their best in a test they don't trust is 
	really assessing properly what they can do.&nbsp; For example, a 
		quick chat in a corridor may tell you lots about a learner's 
		communicative ability but the learner won't feel he/she has  
		been fairly assessed (or assessed at all).<br />
	The environment matters, too.&nbsp; Most learners expect a test to be quite 
	a formal event held in silence with no cooperation between test-takers.&nbsp; 
	If the test is not conducted in this way, some learners may not take it as 
	seriously as others and perform less well than they are able to in other 
	environments.</dd>
			<dt class="auto-style11"><strong>Content validity</strong></dt>
			<dd>If you are planning a course to prepare students for a 
		particular examination, for example, you want your test to represent the 
		sorts of things you need to teach to help them succeed.<br />
			A test which is intended to measure achievement at the end of a 
			course also needs to contain that which has been taught only and not 
			have any extraneous material which has not been the focus of 
			teaching.<br />
			Coverage plays a role here, too, because the more that has been 
			taught, the longer and more comprehensive the test has to be.</dd>
			<dt class="auto-style11"><strong>Predictive 
			<span class="auto-style10">validity</span></strong></dt>
			<dd>Equally, your test should tell you how well your 
		learners will perform in the tasks you set and the lessons you design to help them prepare for the 
		examination.<br />
			For example, if you want to construct a barrier test to see if 
			people are able successfully to follow a course leading to an 
			examination, you will want the test to have good predictive 
			validity.&nbsp; This is not easy to achieve because, until at least 
			one cohort of learners have taken the examination, you cannot know 
			how well the barrier test has worked.&nbsp; Worse, you need to 
			administer the barrier test to a wide range of learners and compare 
			the results of the test with the examination results they actually 
			achieved.&nbsp; This will mean that the barrier test cannot be used 
			to screen out learners until it has been shown to have good 
			predictive validity so the endeavour may take months to come to 
			fruition.</dd>
			<dt class="auto-style11"><strong><span class="auto-style10">Concurrent</span> validity</strong></dt>
			<dd>If, for example, you have a well established proficiency test, 
			such as one administered by experienced examination boards, you may 
			feel that you would be better served with a shorter test that gave 
			you the same sort of data.<br />
			To establish concurrent validity, you need to administer both tests 
			to as large a group as possible and then carefully compare the 
			results.&nbsp; Parallel results are a sign of good concurrent 
			validity and you may be able to dispense with the longer test 
			altogether.<br />
			This may be less important to you but if your test 
		predicts well how learners perform in the examination proper, it will 
		tell you more than if it doesn't.</dd>
			<dt class="auto-style11"><strong>Construct validity</strong></dt>
			<dd>A construct is something that happen in your brain and is not, 
			here, to do with constructing a test.<br />
			To have high construct validity a test-maker must be able succinctly 
			and consistently to answer the question:<br />
			<span class="style_black"><em>&nbsp;&nbsp;&nbsp; What exactly are 
			you testing?</em></span><br />
			If you cannot closely and accurately describe what you are testing, 
			you will not be able to construct a good test.<br />
			It is not enough to answer with something like:<br />
&nbsp;<span class="style_black"><em>&nbsp;&nbsp; I am testing writing ability.</em></span><br />
			because that begs more questions:<br />
			<span class="style_black"><em>&nbsp;&nbsp;&nbsp; At what level?<br />
&nbsp;&nbsp;&nbsp; Concerning what topics?<br />
&nbsp;&nbsp;&nbsp; For which audiences?<br />
&nbsp;&nbsp;&nbsp; In what style?<br />
&nbsp;&nbsp;&nbsp; In what register?<br />
&nbsp;&nbsp;&nbsp; In what length of text?</em></span><br />
			and so on.<br />
			The better able the test designer is to pre-empt those questions by 
			having well-thought-through answers to hand, the higher the level of 
			construct validity the test will have.</dd>
</dl>
			<hr />
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="fresh" height="166" src="../../images/food_breakfast250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Fresh starts</h2>
					</td>
				</tr>
				</table>
			<p>This gets a section to itself, not because it is at the same 
			level of importance but because it affects both reliability and 
			validity.</p>
			<p>If test items are cumulative, the test-takers performance will 
			depend in Task X on how well they achieved Task X-1.&nbsp; In other 
			words, for example, a test which requires a learner to give answers 
			showing comprehension of a reading or listening text and then uses 
			those texts again to test discrete vocabulary items will <strong>not</strong> be:</p>
			<ol class="auto-style6">
				<li>Very reliable because the test-taker may have got lucky and 
				encountered a text with which they were particularly familiar or 
				which happened to contain lexis they knew (among lots they did 
				not know).</li>
				<li>Very valid because the response to the second task will 
				depend on the response to the first task so we do not know if we 
				are measuring the ability we want to test or the ability we have 
				already tested.</li>
			</ol>
			<p>For these reasons, good tests are usually designed so that each 
			item constitutes a fresh start and no test-taker is advantaged by 
			happening to have got lucky with one task that targets something 
			they are particularly good at.</p>
			
			<table cellpadding="0" cellspacing="0">
				<tr>
					<td>
					<img alt="seven" height="166" src="../../images/seven_pieces250.jpg" width="250" /></td>
					<td class="auto-style2">
					<h2>Discrimination</h2>
					</td>
				</tr>
				</table>
			<p>In the world of testing, discrimination is not always a bad 
			thing.<br />
			Here, it refers to the ability which a test has to distinguish 
			clearly and quite finely between different levels of learner.</p>
			<p>If a test is too simple, most of the learners in a group will get 
			most of it right which is good for boosting morale but poor if you 
			want to know who is best and worst at certain tasks.<br />
			Equally, if a test is too difficult, most of the tasks will be 
			poorly achieved and your ability to discriminate between the 
			learners' abilities in any area will be compromised.</p>
			<p>Ideally, all tests should include tasks which will only be fully 
			achieved by the best in a group and allow you to see from the 
			results who they are.&nbsp; The item you include to do this will be 
			called a discriminator.</p>
			<p>Overall, the test has to be targeted at the level of the cohort 
			of students for which it is intended allowing no items which are too 
			easy and none which are undoable by the majority.</p>
			<hr />
			<p><a name="final"></a>Finally, having considered all this, you need to construct your test.&nbsp; How would you go about that?<br />
		<a href="#final" onclick="FP_changeProp(/*id*/'construct',0,'style.visibility','visible')">Think for a 
		moment and make a few notes and then click here</a>.</p>
		<p>
		<img alt="construct a test" id="construct" style="position: relative;  visibility: hidden" height="112" src="../../imagesgraphics/construct_test.png" width="600" /></p>
		<p>Easy.</p>
		<hr />
		<br />
		<table id="istrainingnav" cellpadding="0" class="tableblueborder" cellspacing="0">
			<tr>
				<td class="auto-style21" colspan="2">Related guides<span class="auto-style18"></span></td>
			</tr>
			<tr>
				<td class="auto-style49">
		<a href="../skills/assessing_listening.html">assessing Listening Skills</a></td>
				<td class="auto-style22" rowspan="6">
				these guides assume an understanding of the principles and focus 
				on skills testing</td>
			</tr>
			<tr>
				<td class="auto-style51">
		<a href="../skills/assessing_reading.html">assessing Reading Skills</a></td>
			</tr>
			<tr>
				<td class="auto-style51">
		<a href="../skills/assessing_speaking.html">assessing Speaking Skills</a></td>
			</tr>
			<tr>
				<td class="auto-style44">
		<a href="../skills/assessing_writing.html">assessing Writing Skills</a></td>
			</tr>
			<tr>
				<td class="auto-style50">
				<a href="../teaching/assessing_vocabulary.html">assessing 
				Vocabulary</a></td>
			</tr>
			<tr>
				<td class="auto-style50">
				<a href="../teaching/assessing_grammar.html">assessing Grammar</a></td>
			</tr>
			<tr>
				<td class="auto-style50">
				<a href="../../glossaries/glossary_is_testing.html">testing 
				terminology</a></td>
				<td class="auto-style22">
				for a list of the most common terms used in this area and a link 
				to test for you</td>
			</tr>
			<tr>
				<td class="auto-style50">
				<a href="../../../academic_management/placement.html">placement testing</a></td>
				<td class="auto-style22">
				this is a guide in the Academic Management section concerned 
				with how to place learners in appropriate groups and contains a 
				link to an example 100-item placement test</td>
			</tr>
			<tr>
				<td class="auto-style52">
				<a href="bloom.html">Bloom's taxonomy</a></td>
				<td class="auto-style53">
				this is a way of classifying the cognitive demands that types of 
				test items place on learners</td>
			</tr>
		</table>
		<br />
		<hr />
		<p>Of course, <a href="testing_summary_testhp.htm">there's a test on all of this</a>: 
		some informal, summative evaluation for you.</p>
		<hr />
		<h4>Cambridge <span class="auto-style54">Delta</span></h4>
			<p>If you preparing for Delta Module One, part of the free course 
			for that contains
			<a href="../delta/mod1/m1course/M1_guides/area6_assessment.html" target="_blank">
			a guide to applying the concepts to the examination question</a> 
			(Paper 2, Task 1).<br />
			If you are preparing for Delta Module Three, there's
			<a href="../delta/mod3/elts/m3_testing.html" target="_blank">a guide to how to apply all this</a>.</p>
		<hr />
		<p class="smallfont">References:<br />
		Alderson JC, Hughes, A (Eds.), <em>British Council, ELT Documents 111, Issues 
		in Language Testing,</em> available from
		http://wp.lancs.ac.uk/ltrg/files/2014/05/ILT1981_CommunicativeLanguageTesting.pdf 
		[accessed October 2014]<br />
		Corder, S. P, 1973, <em>Introducing Applied Linguistics</em>, London : 
		Penguin.<br />
		Black, P and Wiliam, D, 2006, <em>Inside The Black Box: Raising 
		Standards Through Classroom Assessment</em>, Granada Learning<br />
		Hughes, A, 1989, <em>Testing for Language Teachers,</em> Cambridge: Cambridge 
		University Press<br />
		Oxford Dictionaries https://languages.oup.com/<br />
		Scrivener, M, 1991, <em>Evaluation thesaurus, 4th edition</em>, Newbury Park, CA: Sage 
		Publications<br />
		<span class="auto-style4">General references for testing and assessment.&nbsp;
			You may find some of the following useful.&nbsp; The text (above) by Hughes 
			is particular clear and accessible:<br />
		Alderson, J. C, 2000,
			<em>Assessing Reading</em>, Cambridge: Cambridge University Press<br />
			Carr, N, 2011, <em>Designing and Analyzing Language Tests: A Hands-on Introduction to 
			Language Testing Theory and Practice</em>, Oxford: Oxford University 
			Press<br />
			Douglas, D, 2000,
			<em>Assessing Languages for Specific Purposes.</em> Cambridge: Cambridge University Press<br />
			Fulcher, G, 2010, <em>Practical Language Testing,</em> London: Hodder Education<br />
			Harris, M &amp; McCann, P, 1994, <em>Assessment,</em> London: Macmillan Heinemann<br />
			Heaton, JB, 1990, <em>Classroom Testing</em>, Harlow: Longman<br />
			Martyniuk, W, 2010,
			<em>Aligning Tests with the CEFR,</em> Cambridge: Cambridge University Press<br />
			McNamara, T, 2000, <em>Language Testing,</em> Oxford: Oxford University Press</span><br />
			<span class="auto-style4">Rea-Dickins, P &amp; Germaine, K, 1992, <em>Evaluation,</em> Oxford: Oxford University Press<br />
			Underhill, N, 1987,
			<em>Testing Spoken Language: A Handbook of Oral Testing Techniques</em>, 
			Cambridge: Cambridge University Press</span></p>
				<hr />
				</div>
	
			<!-- #EndEditable -->
		<!-- End Content -->
	
	<!-- Begin Footer -->
	<div id="footer">
		<p>
		<a href="../../../contact.html">Contact</a> |
		<a href="../../../faq.html">FAQs</a> |
		<a href="../../../copyright_notice.html">Copyright notice</a> |
		<a href="../../../documents/ELT_Concourse_Charter.pdf" target="_blank"> ELT Concourse charter</a> |
		<a href="../../../disclaimer.html"> Disclaimer and Privacy statement </a>|
		<a href="../../../search_the_site.html">Search <strong>
		ELT Concourse</strong></a></p>
	</div>
	<!-- End Footer -->


</body>

<!-- #EndTemplate -->

</html>
